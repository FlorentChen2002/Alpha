## Projet403

**Bin√¥me** : CHEN Florent (21101813), TOROSSI Valentino (28715028)  

**GitHub** : [Lien vers le projet 1](https://github.com/FlorentChen2002/Beta/tree/main)

**Vid√©o** : [Lien vers la vid√©o de d√©monstration du projet 1](https://www.youtube.com/watch?v=nqbnR5M5GTs&ab_channel=FlorentChen)

**GitHub** : [Lien vers le TME 10/11 ](https://github.com/FlorentChen2002/Alpha)

**Vid√©o** : [Lien vers la vid√©o de d√©monstration du tme 10/11](https://www.youtube.com/watch?v=mbJdkHJON4s&ab_channel=FlorentChen)

---
### üöÄ Lancement du projet

Dans la racine du projet, vous trouverez un script **`commande.sh`** qui permet de lancer ou d'arr√™ter le projet en fonction de l'argument pass√© en param√®tre. (il manque le dossier node_modules, car il √©tait trop volumineux)

#### Commandes disponibles :

- `start` : Lance le projet.
- `stop` : Arr√™te le projet.

Exemple d'utilisation du script :

```bash
# Pour d√©marrer le projet
./commande.sh start

# Pour arr√™ter le projet
./commande.sh stop
```
---

## Partie 1 : Infrastructure de base (Strapi, PostgreSQL, Frontend React)

Afin de faciliter l'ex√©cution, la communication entre les conteneurs et la compr√©hension du projet, nous avons d√©cid√© d'utiliser **Docker Compose**.

### Pr√©requis

#### √âtape 1 : D√©ploiement de la base de donn√©es PostgreSQL

Ex√©cuter la commande suivante pour d√©ployer PostgreSQL :

```bash
docker run -dit -p 5432:5432 -e POSTGRES_PASSWORD=safepassword -e POSTGRES_USER=strapi --name strapiDB postgres:latest
```

### √âtape 2 : Cr√©ation du projet Strapi

1. Cr√©er un projet Strapi avec la commande suivante :

   ```bash
   yarn create strapi-app@4.12.0 mon-projet-strapi
   ```
   > ‚ÑπÔ∏è Dans notre cas, le projet s'appelle **`projet-omega`**.
2. Ajouter les fichiers n√©cessaires √† la conteneurisation :
   - Un fichier `Dockerfile`
   - Un fichier `docker-compose.yml`
### √âtape 3 : Cr√©ation d'un mod√®le **Product** et **Event**

Dans l'interface Strapi, cr√©ez une nouvelle collection nomm√© **product** avec les champs suivants :

| Champ              | Type          | Description                                   |
|--------------------|---------------|-----------------------------------------------|
| `name`             | Short text    | Nom du produit                                |
| `description`      | Long text     | Description compl√®te                          |
| `stock_available`  | Integer       | Quantit√© disponible (d√©faut : `0`)            |
| `image`            | Media (image) | Une seule image autoris√©e                     |
| `barcode`          | Short text    | Code-barres du produit                        |
| `status`           | Enumeration   | Valeurs possibles : `safe`, `danger`, `empty` |

cr√©ez une nouvelle collection nomm√© **event** avec les champs suivants :
| Champ       | Type   | Description                       |
|-------------|--------|-----------------------------------|
| `value`     | String | Valeur de l‚Äô√©v√©nement             |
| `metadata`  | JSON   | Informations suppl√©mentaires      |

### √âtape 4 : G√©n√©ration d‚Äôun **Token API**
Cr√©ez un nouveau token en donnant acc√®s aux collections dans strapi

### √âtape 5 : Installation du frontend
1. Se d√©placer dans le dossier du projet :
   ```bash
   cd projet-omega
   yarn install
   ```
2. Cloner le frontend :
   ```bash
   git clone https://github.com/arthurescriou/opsci-strapi-frontend.git
   ```
3. Modifier le fichier `opsci-strapi-frontend/src/conf.ts` :
	- Remplacer l'URL par `http://localhost:1337`
	- Remplacer le token par celui g√©n√©r√© dans Strapi
### √âtape 6 : Mise √† jour du docker compose
Mettre en lien les diff√©rents contenaires √† l'aide du docker compose

## Informations

### Frontend react

- **Nom du projet** : `opsci-strapi-frontend`  
- **Port** : `5173`  
- **Adresse IP locale** : [http://localhost:5173/](http://localhost:5173/)  
- **Nom du conteneur** : `opsci-strapi-frontend`

---

### Strapi

- **Nom du projet** : `projet-omega`  
- **Port** : `1337`  
- **Adresse IP locale** : [http://localhost:1337](http://localhost:1337)  
- **Nom du conteneur** : `strapi`  
- **Nom de la base de donn√©es** : `projet-omega`

---

### Base de donn√©es PostgreSQL

- **Nom du conteneur** : `strapiDB`
- **Port** : `5432` 
- **Image**:`postgres:15`

## Logs et Images

Les logs et les images du projet sont disponibles dans les r√©pertoires suivants :

- **`image_docker_ps`** : Contient les informations sur l'√©tat des conteneurs Docker en cours d'ex√©cution.
- **`image_event_strapi`** : Image relatifs aux √©v√©nements trait√©s par Strapi.
- **`image_prod_strapi`** : Image li√©s √† la gestion des produits dans Strapi.
- **`image_react`** et **`image_react2`**: Image concernant le frontend React de l'application.
- **`log_Bdd`** et **`log_Bdd2`** : Logs de la base de donn√©es, incluant les interactions avec PostgreSQL et Strapi.

---
## Partie 2 : Architecture avec Kafka

On souhaite cr√©er un syst√®me permettant d‚Äôint√©grer de grande quantit√© de donn√©es venant de diff√©rents flux avec beaucoup de r√©silience √† l‚Äôerreur. Donc on va mettre en place une architecture de gestion de flux de donn√©es en temps r√©el √† l‚Äôaide de **Kafka**, en int√©grant **Strapi** pour l‚Äôinterface de gestion des produits et √©v√©nements.

### D√©ploiement de Kafka & Zookeeper  
 Kafka n√©cessite plusieurs **topics** pour fonctionner correctement. Voici les principaux topics utilis√©s dans ce projet :

| Topic   | Description                                                                                  |
|---------|----------------------------------------------------------------------------------------------|
| `product` | Un topic d√©di√© √† la cr√©ation de nouveaux produits en masse, venant de diff√©rentes sources. |
| `event`   | Un topic d√©di√© √† la cr√©ation d'√©v√©nements, en lien avec la gestion des produits.           |
| `stock`   | Un topic pour enregistrer et appliquer tous les mouvements de stocks de nos produits.      |
| `error`   | Un topic pour le stockage des erreurs diverses rencontr√©es lors des √©changes de donn√©es.   |

Installer les Producers & Consumers disponibles danzs le github :
```bash
cd projet-omega
git clone https://github.com/opsci-su/stock-consumer.git
git clone https://github.com/opsci-su/event-producer.git
git clone https://github.com/opsci-su/stock-producer.git
git clone https://github.com/opsci-su/product-producer.git
git clone https://github.com/opsci-su/product-consumer.git
git clone https://github.com/opsci-su/event-consumer.git
```
### Flux de donn√©es avec Kafka

- **Producers** envoient des messages aux **consumers** via Kafka.
- Ces messages sont utilis√©s pour alimenter Strapi avec des donn√©es concernant les produits, les √©v√©nements, et les mouvements de stocks.

### Logs

Les logs des **producers** et **consumers** sont disponibles dans le dossier **log**. Vous y trouverez les fichiers suivants :

- `log_product_consumer` : Logs du consumer pour les produits.
- `log_product_producer` : Logs du producer pour les produits.
- `log_event_consumer` : Logs du consumer pour les √©v√©nements.
- `log_event_producer` : Logs du producer pour les √©v√©nements.
- `log_stock_consumer` : Logs du consumer pour les mouvements de stock.
- `log_stock_producer` : Logs du producer pour les mouvements de stock.

## TME 10-11 : Int√©gration IoT via MQTT et Kafka

Le but de la seconde partie du projet, est de mettre en place un support de communication permettant √† un objet connect√© (via MQTT) de mettre √† jour le stock d‚Äôun produit, et que cette info remonte jusqu‚Äô√† Strapi, gr√¢ce √† Kafka.

---
### Pr√©requis

1. Mettre en place un scripte dans /mosquitto/mosquitto.conf
```conf
persistence true
persistence_location /mosquitto/data/
log_dest file /mosquitto/log/mosquitto.log
allow_anonymous true
listener 1883
protocol websockets
```
2. Configurer le docker compose en ajoutant le lancement du scripte mosquitto et de la connexion avec kafka

---

### Architecture mise en place

**Frontend (MQTT over WebSocket)**
   ‚Üì
**Mosquitto** *(broker MQTT)*
   ‚Üì
**Connecteur MQTT ‚Üí Kafka** *(arthurescriou/mqtt-kafka-connector)*
   ‚Üì
**Kafka** *(topic: `stock`)*
   ‚Üì
**Consumer Kafka**
   ‚Üì
**Strapi** *(mise √† jour du stock produit)*


---

### D√©roul√© de la cha√Æne

1. Le **navigateur** publie un message MQTT vers **Mosquitto**, via WebSocket (port `1883`) (site:`https://mqtt-test-front.onrender.com/` ).
2. Le **connecteur** `mqtt-kafka-connector` √©coute le topic MQTT `"topic"` et publie le message dans le topic Kafka `"stock"`.
3. Un **consumer Kafka** lit le message et effectue une requ√™te vers le **Strapi** pour mettre √† jour le stock du produit correspondant.
4. Le **changement de stock** est alors visible dans le **dashboard Strapi** et dans le **Frontend**.

### Logs

- `log_mosquitto_connexion` : Logs des r√©ceptions des messages et la transmission des messages √† kafka.
- `log_stock_consumer_mqtt` : Logs du consumer pour les mouvements de stock.